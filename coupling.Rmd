---
title: "Spatial coupling in measles via fade-out survival analysis"
csl: ecology.csl
output:
  html_document:
    code_folding: show
    df_print: kable
    highlight: tango
    dev: png
    number_sections: no
    toc: yes
    toc_depth: 2
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: yes
    toc_depth: 2
    dev: png
    df_print: kable
bibliography: gravity.bib
---

\newcommand\prob[1]{\mathbb{P}\left[{#1}\right]}
\newcommand\expect[1]{\mathbb{E}\left[{#1}\right]}
\newcommand\var[1]{\mathrm{Var}\left[{#1}\right]}
\newcommand\dist[2]{\mathrm{#1}\left(#2\right)}
\newcommand\dlta[1]{{\Delta}{#1}}
\newcommand\lik{\mathscr{L}}
\newcommand\loglik{\ell}

Produced with **R** version `r getRversion()`.

--------------------------

```{r knitr-opts,include=FALSE,cache=FALSE}
library(knitr)
prefix <- "coupling"
opts_chunk$set(
  eval=TRUE,
  purl=FALSE,
  progress=TRUE,
  prompt=FALSE,tidy=FALSE,highlight=TRUE,
  strip.white=TRUE,
  warning=FALSE,
  message=FALSE,
  error=FALSE,
  echo=TRUE,
  cache=TRUE,
  cache.extra=rand_seed,
  results='markup',
  fig.show='asis',
  size='small',
  fig.lp="fig:",
  fig.path=paste0("figure/",prefix,"-"),
  cache.path=paste0("cache/",prefix,"-"),
  fig.pos="h!",
  fig.align='center',
  fig.height=4,fig.width=6.83,
  dpi=300,
  dev='png',
  dev.args=list(bg='transparent')
  )
read_chunk("tsir.R")
read_chunk("modelfits.R")
```

# Preparations

```{r prelims,cache=FALSE}
options(
  keep.source=TRUE,
  stringsAsFactors=FALSE,
  knitr.kable.NA="",
  encoding="UTF-8")

set.seed(594709947L)

library(grid)
library(plyr)
library(reshape2)
library(magrittr)
library(foreach)
library(iterators)
library(bbmle)
library(nloptr)
library(pomp)
library(ggplot2)
theme_set(theme_bw())
library(doMC)
registerDoMC()
```

## Preprocess the data.

Retrieve the data from the database.

```{r clean-data,eval=FALSE}
```

In the above:

1. Measles data is weekly; dates given correspond to Sunday.
1. Associate each week's data with the Weds. of that week.
1. Discard any 53rd weeks (1947,1952,1958,1964).
1. Aggregate by biweek (26 biweeks/yr).
1. Join with demographic data.
1. Scale birth rates to births/biweek.

Now let's compute the distances between the cities.

```{r distances,eval=FALSE}
```

## Apply TSIR model to the individual towns.

### Susceptible reconstruction.

Smoothing spline regression of cumulative cases on cumulative births to estimate under-reporting and residuals.
Correct for under-reporting: `I = cases/ur`.

Regress cumulative cases on cumulative births to estimate under-reporting (ur) and susceptible depletion (`z`) `I` is estimated as `cases/ur`.

```{r under-reporting,eval=FALSE}
```

Now reconstruct the susceptibles (via the residuals `z`).

```{r susceptible-reconstruction,eval=FALSE}
```

*Does the preceding scale the z variable appropriately?*
*I.e., does it take under-reporting into account?*

### Fit TSIR

First, set up the data matrix for the regression.
This involves lagging the I and z variables.
Population size is assumed constant at its median value.

```{r make-data-matrix,eval=FALSE}
```

We'll start by estimating the mean susceptible fraction, assuming a single global value for this parameter.
Some towns have very high changes in susceptible fraction; exclude these.

```{r exclude-weird-towns,eval=FALSE}
```

Now profile on the fraction, $\sigma$, of susceptibles in the population.
This assumes a single, global value of $\sigma$.
**NOTE: the $\beta$ are here scaled by population size.**

```{r sigma-profile,eval=FALSE}
```
```{r sigma-profile-plot}
readRDS("sigma-bar.rds") -> sigmaBar
readRDS("sigma-profile.rds") %>%
    ggplot(aes(x=sigma,y=dev))+geom_line()
```

Our global sigma estimate is $\sigma=`r signif(sigmaBar,3)`$.
Now, we assume this value of $\sigma$ and fit TSIR to each of the towns individually using linear regression.

```{r fit-tsir}
```

Just for interest, let's plot $R_0$ as a function of city size.

```{r R0-plot}
library(scales)
dat %>% ddply(~town,summarize,N=mean(Ps),
              beta=exp(mean(log.beta)),R0=beta*N) %>%
    ggplot(aes(x=N,y=R0))+geom_point()+
    scale_x_log10(breaks=10^seq(2,7),
                  labels=trans_format('log10',math_format(10^.x)))+
    scale_y_log10(breaks=seq(1,30))+
    labs(x="Population size",y=expression(R[0]))+
    theme_classic()
```

- `Shat` is fitted to each individually.
- `Sbar` is fitted globally (with some towns excluded).

# Coupling the cities.

Let $X_{i}(t)$ be the observation at time $t$ in city $i$.
We assume that
$$X_{i}(t+1) \sim \dist{Poisson}{\lambda_i(t)}$$ 
or, alternatively,
$$X_{i}(t+1) \sim \dist{NegBinom}{\lambda_i(t),\frac{1}{\psi}},$$
where $\psi$ is an overdispersion parameter.
In the latter, we have parameterized the negative binomial distribution so that
$\expect{X_i(t+1)}=\lambda_i(t)$ and $\var{X_i(t+1)}=\lambda_i(t)+\psi\,\lambda_i(t)^2$.

When $I_i(t)=0$, we have that
$$\lambda_i(t) = \beta_i(t)\,S_i(t)\,\iota_i(t)^\alpha.$$
In the above, $\beta$ is constructed by fitting the TSIR model to each city independently and the susceptible pool, $S$, is reconstructed using TSIR methods.
The quantity $\iota$ is the import rate, which we estimate using a variety of different models.

The following computes $y$, $S$, $\beta$, and the matrix of reciprocal distances.
It also picks out the relevant observations.
These are the ones for which the preceding week saw zero cases.


```{r gravity-pre}
```

# The gravity model

The gravity model (with intercept) is
$$\iota_i=N_i^{\tau_1} \left(\theta\,\sum_{j\ne i}\! N_j^{\tau_2} d_{ij}^{-\rho}\,\frac{I_j}{N_j}+\phi\right).$$
Let
$$Q_{ij}=\begin{cases}N_i^{\tau_2}\,d_{ij}^{-\rho}, &i\ne j\\0, &i=j\end{cases}$$ and
$$y_{i}=\frac{I_i}{N_i}.$$

Expressed compactly, the gravity model is
$$\iota = \theta\,\mathrm{diag}(N^{\tau_1})\,Q^T\,y+\phi\,N^{\tau_1}.$$

We use **R**'s element-recycling feature, which allows us to write
$$\mathrm{diag}(A)\,B=A\;*\;B.$$


The negative log likelihood function for the gravity model is:
```{r gravity-like}
```

Now we'll do a likelihood profile over $\tau_1$ and $\tau_2$.

```{r gravity-profile-2D,cache=FALSE}
```

The above was completed in `r round(attr(results,"system.time")[3]/60,1)`&nbsp;min on a `r attr(results,"nproc")`-core cluster.
Now we refine to obtain the global MLE.

```{r gravity-mle,cache=FALSE}
bake("gravity-mle.rds",{
  
  results %>%
    extract(!sapply(results,inherits,"try-error")) %>%
    ldply() %>%
    subset(loglik==max(loglik),select=-c(loglik,conv)) -> start
  
  mle2(likfnGravity,
    method="Nelder-Mead",
    start=as.list(start),
    control=list(trace=0,maxit=10000),
    skip.hessian=TRUE) -> fit
  
  c(coef(fit),loglik=as.numeric(logLik(fit)),
    conv=fit@details$convergence) %>%
    as.list() %>%
    as.data.frame() -> mle
}) -> mle.grav
```

```{r gravity-results}
results %>%
  extract(sapply(results,inherits,"try-error")) %>%
  sapply(as.character) %>%
  unique()

results %<>%
  extract(!sapply(results,inherits,"try-error")) %>%
  ldply() %>%
  mutate(rho=exp(rho),theta=exp(theta),psi=exp(psi),phi=exp(phi))

results %>% count(~conv)

results %>%
  ggplot(aes(x=tau1,y=tau2,z=loglik,
    fill=ifelse(loglik>max(loglik)-2000,loglik,NA)))+
  geom_tile(color=NA)+geom_contour(bins=100,color='white')+
  geom_point(color='red',shape="x",size=3,data=mle.grav)+
  geom_hline(color='red',size=0.2,linetype=2,data=mle.grav,aes(yintercept=tau2))+
  geom_vline(color='red',size=0.2,linetype=2,data=mle.grav,aes(xintercept=tau1))+
  labs(x=expression(tau[1]),y=expression(tau[2]),fill=expression(log(L)))
```

Regarding NLOPT return values:

**Successful termination (positive return values)**

- NLOPT_SUCCESS = 1
Generic success return value.
- NLOPT_STOPVAL_REACHED = 2
Optimization stopped because stopval (above) was reached.
- NLOPT_FTOL_REACHED = 3
Optimization stopped because ftol_rel or ftol_abs (above) was reached.
- NLOPT_XTOL_REACHED = 4
Optimization stopped because xtol_rel or xtol_abs (above) was reached.
- NLOPT_MAXEVAL_REACHED = 5
Optimization stopped because maxeval (above) was reached.
- NLOPT_MAXTIME_REACHED = 6
Optimization stopped because maxtime (above) was reached.

**Error codes (negative return values)**

- NLOPT_FAILURE = -1
Generic failure code.
- NLOPT_INVALID_ARGS = -2
Invalid arguments (e.g. lower bounds are bigger than upper bounds, an unknown algorithm was specified, etcetera).
- NLOPT_OUT_OF_MEMORY = -3
Ran out of memory.
- NLOPT_ROUNDOFF_LIMITED = -4
Halted because roundoff errors limited progress. (In this case, the optimization still typically returns a useful result.)
- NLOPT_FORCED_STOP = -5
Halted because of a forced termination: the user called nlopt_force_stop(opt) on the optimization’s  nlopt_opt object opt from the user’s objective function or constraints.

```{r gravity-pairsplot,fig.height=6.83}
pairs(~loglik+theta+phi+rho+psi+tau1+tau2,
      data=results,
      subset=loglik>max(loglik)-10000,cex=0.5)
```

# The Xia (wonky gravity) model

The model of @xia2004measles is
$$\iota_i=N_i^{\tau_1}\,\left(\theta\,\sum_{j\ne i}\! I_j^{\tau_2} d_{ij}^{-\rho} + \phi\right).$$
Let
$$Q_{ij}=\begin{cases}N_i^{\tau_2}\,d_{ij}^{-\rho}, &i\ne j\\0, &i=j\end{cases}$$ and
$$y_{i}=\frac{I_i}{N_i}.$$

Expressed compactly, the @xia2004measles model is
$$\iota = \theta\,\mathrm{diag}(N^{\tau_1})\,Q^T\,y^{\tau_2}+\phi\,N^{\tau_1}.$$

The negative log likelihood function for the @xia2004measles model is:

```{r xia-like}
```

Again, a profile computation.

```{r xia-profile-2D,cache=FALSE}
```

The above was completed in `r round(attr(results,"system.time")[3]/60,1)`&nbsp;min on a `r attr(results,"nproc")`-core cluster. 

```{r xia-mle,cache=FALSE}
bake("xia-mle.rds",{
  results %>%
    extract(!sapply(results,inherits,"try-error")) %>%
    ldply() %>%
    subset(loglik==max(loglik),select=-c(loglik,conv)) -> start
  
  mle2(likfnXia,
    method="Nelder-Mead",
    start=as.list(start),
    control=list(trace=0,maxit=10000),
    skip.hessian=TRUE) -> fit
  
  c(coef(fit),loglik=as.numeric(logLik(fit)),
    conv=fit@details$convergence) %>%
    as.list() %>%
    as.data.frame() -> mle
}) -> mle.xia
```

```{r xia-results}
results %>%
  extract(sapply(results,inherits,"try-error")) %>%
  sapply(as.character) %>%
  unique()

results %<>%
  extract(!sapply(results,inherits,"try-error")) %>%
  ldply() %>%
  mutate(rho=exp(rho),theta=exp(theta),psi=exp(psi),phi=exp(phi))

results %>%
  ggplot(aes(x=tau1,y=tau2,z=loglik,
    fill=ifelse(loglik>max(loglik)-2000,loglik,NA)))+
  geom_tile(color=NA)+geom_contour(bins=100,color='white')+
  geom_point(color='red',shape="x",size=3,data=mle.xia)+
  geom_hline(color='red',size=0.2,linetype=2,data=mle.xia,aes(yintercept=tau2))+
  geom_vline(color='red',size=0.2,linetype=2,data=mle.xia,aes(xintercept=tau1))+
  labs(x=expression(tau[1]),y=expression(tau[2]),fill=expression(log(L)))
```

```{r xia-pairsplot,fig.height=6.83}
pairs(~loglik+theta+phi+rho+psi+tau1+tau2,
      data=results,
      subset=loglik>max(loglik)-10000,cex=0.5)
```

# Competing destinations model

The competing destinations model is
$$\iota_i=N_i^{\tau_1}\,\left(\theta\,\sum_j\frac{N_j^{\tau_2}}{d_{ij}^\rho}\,\left(\sum_{k \ne i, j}\frac{N_k^{\tau_2}}{d_{jk}^\rho}\right)^\delta\,\frac{I_j}{N_j}+\phi\right).$$

Let
$$Q_{ij}=\begin{cases}{N_i^{\tau_2}}{d_{ij}^{-\rho}}, &i\ne j\\0, &i=j\end{cases}$$ and
$$R_{ji}=\sum_{k \ne i, j}{N_k^{\tau_2}}{d_{jk}^{-\rho}}=\sum_{k\ne i,j}Q_{kj}=\sum_{k\ne i}Q_{kj}=\sum_{k}Q_{kj}-Q_{ij}.$$
This implies
$$R^T=(\mathbb{1}\,\mathbb{1}^T-I)\,Q \qquad \Longleftrightarrow \qquad R=Q^T\,(\mathbb{1}\,\mathbb{1}^T-I)$$
and
$$\iota_i=N_i^{\tau_1}\,\left(\theta\,\sum_j Q_{ji}\,R_{ji}^\delta\,y_{j}+\phi\right).$$

The negative log likelihood function for the competing destinations model is:

```{r compdest-like}
```

We compute the profile likelihood as before.

```{r compdest-profile-2D,cache=FALSE}
```

The above was completed in `r round(attr(results,"system.time")[3]/60,1)`&nbsp;min on a `r attr(results,"nproc")`-core cluster. 

```{r compdest-mle,cache=FALSE}
bake("compdest-mle.rds",{
  
  results %>%
    extract(!sapply(results,inherits,"try-error")) %>%
    ldply() %>%
    subset(loglik==max(loglik),select=-c(loglik,conv)) -> start
  
  mle2(likfnCompDest,
    method="Nelder-Mead",
    start=as.list(start),
    control=list(trace=0,maxit=10000),
    skip.hessian=TRUE) -> fit
  
  c(coef(fit),loglik=as.numeric(logLik(fit)),
    conv=fit@details$convergence) %>%
    as.list() %>%
    as.data.frame() -> mle
}) -> mle.compdest
```


```{r compdest-results}
results %>%
  extract(sapply(results,inherits,"try-error")) %>%
  sapply(as.character) %>%
  unique()

results %<>%
  extract(!sapply(results,inherits,"try-error")) %>%
  ldply() %>%
  mutate(rho=exp(rho),theta=exp(theta),psi=exp(psi),phi=exp(phi))

results %>%
  ggplot(aes(x=tau1,y=tau2,z=loglik,
    fill=ifelse(loglik>max(loglik)-2000,loglik,NA)))+
  geom_tile(color=NA)+geom_contour(bins=100,color='white')+
  geom_point(color='red',shape="x",size=3,data=mle.compdest)+
  geom_hline(color='red',size=0.2,linetype=2,data=mle.compdest,aes(yintercept=tau2))+
  geom_vline(color='red',size=0.2,linetype=2,data=mle.compdest,aes(xintercept=tau1))+
  labs(x=expression(tau[1]),y=expression(tau[2]),fill=expression(log(L)))
```

```{r compdest-pairsplot,fig.height=6.83}
pairs(~loglik+theta+phi+rho+delta+psi+tau1+tau2,
      data=results,
      subset=loglik>max(loglik)-10000,cex=0.5)
```

# Stouffer model

Let $i$ be the recipient town; $j$, the donor.
Let $S(i,j)$ be the collection of towns closer to town $i$ than $j$ is.
That is, $S(i,j) = \{k: k\ne i \ \&\ d(i,k) \le d(i,j)\}$.

$$\iota_i = N_i^{\tau_1}\,\left(\theta\,\sum_j\!\left(\frac{N_j}{\sum_{k\in S(i,j)}{N_k}}\right)^{\tau_2}\,\frac{I_j}{N_j}+\phi\right).$$


```{r rankmat,cache=FALSE}
```

The negative log likelihood function for the @xia2004measles model is:

```{r stouffer-like}
```

We compute the profile likelihood as before.

```{r stouffer-profile-2D,cache=FALSE}
```

The above was completed in `r round(attr(results,"system.time")[3]/60,1)`&nbsp;min on a `r attr(results,"nproc")`-core cluster. 

```{r stouffer-mle,cache=FALSE}
bake("stouffer-mle.rds",{
  
  results %>%
    extract(!sapply(results,inherits,"try-error")) %>%
    ldply() %>%
    subset(loglik==max(loglik),select=-c(loglik,conv)) -> start
  
  mle2(likfnStouffer,
    method="Nelder-Mead",
    start=as.list(start),
    control=list(trace=0,maxit=10000),
    skip.hessian=TRUE) -> fit
  
  c(coef(fit),loglik=as.numeric(logLik(fit)),
    conv=fit@details$convergence) %>%
    as.list() %>%
    as.data.frame() -> mle
}) -> mle.stouffer
```

```{r stouffer-results}
results %>%
  extract(sapply(results,inherits,"try-error")) %>%
  sapply(as.character) %>%
  unique()

results %<>%
  extract(!sapply(results,inherits,"try-error")) %>%
  ldply() %>%
  subset(is.finite(loglik)) %>%
  mutate(theta=exp(theta),psi=exp(psi),phi=exp(phi))

results %>%
  ggplot(aes(x=tau1,y=tau2,z=loglik,
    fill=ifelse(loglik>max(loglik)-2000,loglik,NA)))+
  geom_tile(color=NA)+geom_contour(bins=100,color='white')+
  geom_point(color='red',shape="x",size=3,data=mle.stouffer)+
  geom_hline(color='red',size=0.2,linetype=2,data=mle.stouffer,aes(yintercept=tau2))+
  geom_vline(color='red',size=0.2,linetype=2,data=mle.stouffer,aes(xintercept=tau1))+
  labs(x=expression(tau[1]),y=expression(tau[2]),fill=expression(log(L)))
```

```{r stouffer-pairsplot,fig.height=6.83}
pairs(~loglik+theta+phi+psi+tau1+tau2,
      data=results,
      subset=loglik>max(loglik,na.rm=TRUE)-10000,cex=0.5)
```

## Variant: Stouffer model with recipient included

Let $i$ be the recipient town; $j$, the donor.
Let $S'(i,j)$ be the collection of towns closer to town $i$ than $j$ is.
That is, $S'(i,j) = \{k: d(i,k) \le d(i,j)\}$.
Note that $S'(i,j)$ includes $i$, whilst $S(i,j)$ does not. 

$$\iota_i = N_i^{\tau_1}\,\left(\theta\,\sum_j\!\left(\frac{N_j}{\sum_{k\in S'(i,j)}{N_k}}\right)^{\tau_2}\,\frac{I_j}{N_j}+\phi\right)$$


```{r rankmat1,cache=FALSE}
```

```{r stouffer1-like}
```

The profile likelihood computation.

```{r stouffer1-profile-2D,cache=FALSE}
```

The above was completed in `r round(attr(results,"system.time")[3]/60,1)`&nbsp;min on a `r attr(results,"nproc")`-core cluster. 

```{r stouffer1-mle,cache=FALSE}
bake("stouffer1-mle.rds",{
  
  results %>%
    extract(!sapply(results,inherits,"try-error")) %>%
    ldply() %>%
    subset(loglik==max(loglik),select=-c(loglik,conv)) -> start
  
  mle2(likfnStouffer1,
    method="Nelder-Mead",
    start=as.list(start),
    control=list(trace=0,maxit=10000),
    skip.hessian=TRUE) -> fit
  
  c(coef(fit),loglik=as.numeric(logLik(fit)),
    conv=fit@details$convergence) %>%
    as.list() %>%
    as.data.frame() -> mle
}) -> mle.stouffer1
```

```{r stouffer1-results}
results %>%
  extract(sapply(results,inherits,"try-error")) %>%
  sapply(as.character) %>%
  unique()

results %<>%
    extract(!sapply(results,inherits,"try-error")) %>%
    ldply() %>%
    subset(is.finite(loglik))

results %>%
  ggplot(aes(x=tau1,y=tau2,z=loglik,
    fill=ifelse(loglik>max(loglik)-2000,loglik,NA)))+
  geom_tile(color=NA)+geom_contour(bins=100,color='white')+
  geom_point(color='red',shape="x",size=3,data=mle.stouffer1)+
  geom_hline(color='red',size=0.2,linetype=2,data=mle.stouffer1,aes(yintercept=tau2))+
  geom_vline(color='red',size=0.2,linetype=2,data=mle.stouffer1,aes(xintercept=tau1))+
  labs(x=expression(tau[1]),y=expression(tau[2]),fill=expression(log(L)))
```

```{r stouffer1-pairsplot,fig.height=6.83}
pairs(~loglik+theta+phi+psi+tau1+tau2,
      data=results,
      subset=loglik>max(loglik,na.rm=TRUE)-10000,cex=0.5)
```


# Radiation model

$$\iota_i=\theta \sum_j N_j \frac{N_j N_i}{(N_j + \sum_{k \in S(i,j)} N_k)(N_j + N_i + \sum_{k \in S(i,j)} N_k)} \frac{I_j}{N_j}$$

```{r radmat,cache=FALSE}
```

```{r radiation-like}
likfnRadiation <- function (theta, psi) {
  theta <- exp(theta)
  iota <- theta*(rr%*%ylag)
  lambda <- betaS*iota[relevant]^alpha
  -sum(dnbinom(x=obs,mu=lambda,size=exp(-psi),log=TRUE))
}
```

```{r radiation-mle,cache=FALSE}
bake(file="radiation-mle.rds",{
  mle2(likfnRadiation,
    method="Nelder-Mead",
    start=list(theta=log(1),psi=log(5)),
    control=list(trace=0,maxit=10000),
    skip.hessian=FALSE)
}) -> fit
```

```{r radiation-results}
summary(fit)
logLik(fit)
c(coef(fit),loglik=logLik(fit)) %>%
  as.list() %>% as.data.frame() -> mle.radiation
```

## Variant: radiation model with recipient included

$$\iota_i=\theta \sum_j N_j \frac{N_j N_i}{(N_j + \sum_{k \in S'(i,j)} N_k)(N_j + N_i + \sum_{k \in S'(i,j)} N_k)} \frac{I_j}{N_j}$$

```{r radmat1,cache=FALSE}
```

```{r radiation1-like}
likfnRadiation1 <- function (theta, psi) {
  theta <- exp(theta)
  iota <- theta*(rr%*%ylag)
  lambda <- betaS*iota[relevant]^alpha
  -sum(dnbinom(x=obs,mu=lambda,size=exp(-psi),log=TRUE))
}
```

```{r radiation1-mle,cache=FALSE}
bake(file="radiation1-mle.rds",{
  mle2(likfnRadiation1,
    method="Nelder-Mead",
    start=list(theta=log(1),psi=log(5)),
    control=list(trace=0,maxit=10000),
    skip.hessian=FALSE)
}) -> fit
```

```{r radiation1-results}
summary(fit)
logLik(fit)
c(coef(fit),loglik=logLik(fit)) %>%
  as.list() %>% as.data.frame() -> mle.radiation1
```


# Model comparison

```{r modelcomp,cache=FALSE,echo=FALSE}
list(gravity=mle.grav,
     xia=mle.xia,
     comp.dest=mle.compdest,
     stouffer=mle.stouffer,
     stouffer.variant=mle.stouffer1,
     radiation=mle.radiation,
     radiation.variant=mle.radiation1) %>%
  ldply(.id="model") %>%
  arrange(-loglik) %>%
  mutate(rho=exp(rho),psi=exp(psi),delta.loglik=loglik-max(loglik)) %>%
  subset(select=c(model,loglik,delta.loglik,theta,phi,rho,tau1,tau2,delta,psi)) %>%
  rename(c(theta="$\\log{\\theta}$",phi="$\\log{\\phi}$",rho="$\\rho$",
    psi="$\\psi$",tau1="$\\tau_1$",tau2="$\\tau_2$",delta="$\\delta$",
    loglik="$\\ell$",delta.loglik="$\\Delta\\!\\ell$")) %>%
  kable(digits=3)
```

# Diagnostics

To study whether better statistical fit translates to meaningful improvement on prediction on incidence we can look at CCS patterns:

```
dat$E=dat$cases==0 
dat %>% ddply(~town,summarize,mean(E)) -> ext
plot(ext[,2]~N)
```

We can predict importation rates from fitted models

```{r iota-plot,fig.height=6.83,eval=FALSE}
#Gravity
readRDS("gravity-mle.rds") -> test

cfs=with(as.list(coef(test)),c(exp(c(theta=theta,rho=rho)),tau1=tau1,tau2=tau2))

Q<-with(as.list(cfs),
 (N^tau2)*(dd^rho)
)

iotagr<-apply(
with(as.list(cfs),
  theta*(N^tau1)*crossprod(Q,ylag)
),1,mean)

plot(iotagr~N, log="xy", ylab="imports")

#Xia
readRDS("xia-test.rds") -> test

summary(test)

cfs<-with(as.list(coef(test)),c(exp(c(theta=theta,rho=rho)),tau1=tau1,tau2=tau2))
 Q <- with(as.list(cfs),
 (N^tau2)*(dd^rho))

iotaxi<-apply(
with(as.list(cfs),
  theta*(N^tau1)*crossprod(Q,ylag^tau2)
),1,mean)

points(iotaxi~N, col=2)

#CD
bake(file="compdest-test.rds",{
    tic <- Sys.time()
    test <- mle2(likfnCompDest,
                 method="Nelder-Mead",
                 start=par,
                 control=list(trace=0,maxit=4000))
    toc <- Sys.time()
    toc-tic
    test
}) -> test

cfs<-with(as.list(coef(test)),c(exp(c(theta=theta,rho=rho)),delta=delta,tau1=tau1,tau2=tau2))
 Q <- with(as.list(cfs),
 (N^tau2)*(dd^rho))

iii <- 1-diag(length(N))

 R <- with(as.list(cfs),
 crossprod(Q,iii)^delta)

iotacd<-apply(
with(as.list(cfs),
theta*(N^tau1)*crossprod(Q*R,ylag)
),1,mean)

points(iotacd~N, col=3)

#Stouffer
bake(file="rankmat.rds",{
  rr <- array(dim=dim(distances),dimnames=dimnames(distances))
  for (i in seq_along(N)) {
    for (j in seq_along(N)) {
      rr[i,j] <- N[j]/(sum(N[distances[i,]<=distances[i,j]])-N[i])
    }
  }
  diag(rr) <- 0
  rr
}) -> rr

bake(file="stouffer-test.rds",{
    tic <- Sys.time()
    test <- mle2(likfnStouffer,
                 method="Nelder-Mead",
                 start=par,
                 control=list(trace=0,maxit=4000))
    toc <- Sys.time()
    toc-tic
    test
}) -> test


cfs<-with(as.list(coef(test)),c(exp(c(theta=theta)),tau1=tau1,tau2=tau2))

iotast <-apply(
with(as.list(cfs), theta*(N^tau1)*((rr^tau2)%*%ylag)
),1,mean)
points(iotast~N, col=5)



#Stouffer variant
bake(file="rankmat1.rds",{
  rr <- array(dim=dim(distances),dimnames=dimnames(distances))
  for (i in seq_along(N)) {
    for (j in seq_along(N)) {
      rr[i,j] <- N[j]/sum(N[distances[i,]<=distances[i,j]])
    }
  }
  diag(rr) <- 0
  rr
}) -> rr

bake(file="stouffer1-test.rds",{
    tic <- Sys.time()
    test <- mle2(likfnStouffer1,
                 method="Nelder-Mead",
                 start=par,
                 control=list(trace=0,maxit=4000))
    toc <- Sys.time()
    toc-tic
    test
}) -> test


cfs<-with(as.list(coef(test)),c(exp(c(theta=theta)), tau1=tau1,tau2=tau2))

iotavs <-apply(
with(as.list(cfs), theta*(N^tau1)*((rr^tau2)%*%ylag)
),1,mean)
points(iotavs~N, col=5)

#Radiation
bake(file="radmat.rds",{
  rr <- array(dim=dim(distances),dimnames=dimnames(distances))
  for (i in seq_along(N)) {
    for (j in seq_along(N)) {
      s <- sum(N[distances[i,]<=distances[i,j]])
      rr[i,j] <- N[i]*N[j]*N[j]/s/(s-N[i])
    }
  }
  diag(rr) <- 0
  rr
}) -> rr

bake(file="radiation.rds",{
  mle2(likfnRadiation,
       method="Brent",
       lower=-20,upper=20,
       start=par,
       control=list(trace=0,maxit=4000))
}) -> fit

cfs=with(as.list(coef(fit)),c(exp(c(theta=theta))))
iotara <-apply(
with(as.list(cfs), theta*(rr%*%ylag)
),1,mean)

#Radiation Variant
bake(file="radmat1.rds",{
  rr <- array(dim=dim(distances),dimnames=dimnames(distances))
  for (i in seq_along(N)) {
    for (j in seq_along(N)) {
      s <- sum(N[distances[i,]<=distances[i,j]])
      rr[i,j] <- N[i]*N[j]*N[j]/(s+N[i])/(s)
    }
  }
  diag(rr) <- 0
  rr
}) -> rr

bake(file="radiation1.rds",{
  mle2(likfnRadiation1,
       method="Brent",
       lower=-20,upper=20,
       start=par,
       control=list(trace=0,maxit=4000))

}) -> test

cfs<-with(as.list(coef(test)),c(exp(c(theta=theta))))
iotavr <-apply(
with(as.list(cfs), theta*(rr%*%ylag)
),1,mean)

points(iotavr~N, col=6)
legend("topleft",
       legend=c("Gravity", "Xia", "Compdest",
                "X Compdest", "V Stouffer", "V Radiat"),
       pch=rep(21,6),
        col=1:6)

```

We next create the fade-out plot
```{r fadeout-plot,fig.height=6.83}
dat$E=dat$cases==0 
dat %>% ddply(~town,summarize,mean(E)) -> ext

par(mfrow=c(1,1))
par(mar = c(5,5,2,5))
plot(ext[,2]~N, log="x", xlab="Pop.size", ylab="Presence")

par(new=T)

plot(log(ext[,2]/(1-ext[,2]))~N, log="x",type="p", col="red", axes=FALSE, xlab=NA, ylab=NA)
axis(side = 4)
mtext(side = 4, line = 4, "logit")
legend("topright",
       legend=c("Presence", "logit"),
       pch=c(21,21),
        col=c("black", "red"))
```
And do spatial plot of residuals 
```{r residual-plot,fig.height=6.83,eval=F}
library(ncf)
dfr=data.frame(lon=latlon$Long, lat=latlon$Lat, gr=iotagr, cd=iotacd, res=iotagr-iotacd)
spatial.plot(dfr$lon, dfr$lat, edat$resE, inches=.1)
title("excess fade-out")
```
Then generate deviations ffrom expectation based on size for all of the spatial models.
```{r expect-spatial,eval=F}
edat=data.frame(N=N, E=ext, logitE=log(ext[,2]/(1-ext[,2])), 
gr=iotagr,
xi=iotaxi,
cd=iotacd,
wc=iotawc,
st=iotast,
vs=iotavs,
ra=iotara,
vr=iotavr
)
```

And create residuals of all against log(N)

```{r residuals,eval=F}
edat$logitE[edat$logitE==-Inf]=NA
edat$resE=NA
edat$resE[!is.na(edat$logitE)]=resid(lm(logitE~I(log(N)), data=edat, na.action=na.omit))
edat%<>%mutate(resGR=resid(lm(log(gr)~I(log(N)))))
edat%<>%mutate(resXI=resid(lm(log(xi)~I(log(N)))))
edat%<>%mutate(resCD=resid(lm(log(cd)~I(log(N)))))
edat%<>%mutate(resWC=resid(lm(log(wc)~I(log(N)))))
edat%<>%mutate(resST=resid(lm(log(st)~I(log(N)))))
edat%<>%mutate(resVS=resid(lm(log(vs)~I(log(N)))))
edat%<>%mutate(resRA=resid(lm(log(ra)~I(log(N)))))
edat%<>%mutate(resVR=resid(lm(log(vr)~I(log(N)))))
```
The correlation among residuals
```{r cormat,eval=F}
round(cor(edat[,13:21], use="pairwise.complete"), 3)
```
Clearly the Comp-Dest versions are best.

```{r corr plot,eval=F}
cc=matrix(NA, ncol=3, nrow=8)
for(i in 1:8){
  cc[i,]=cor.test(-edat[,13], edat[,13+i])$estimate
  cc[i,2:3]=cor.test(-edat[,13], edat[,13+i])$conf.int[1:2]
}
cc=as.data.frame(cc)
dimnames(cc)=list(c("GR", "XI", "CD", "xC", "ST", "SV", "RA", "RV"), c("Est", "L", "U"))

library(plotrix)
plotCI(cc[,1], ui=cc[,3], li=cc[,2], ylab="cor", xlab="")
#text(1:8,0,c("GR", "XI", "CD", "xC", "ST", "SV", "RA", "RV"))
axis(1, at=1:8, labels=c("GR", "XI", "CD", "xC", "ST", "SV", "RA", "RV"))
```
Plot of difference between Xia and xCD
```{r difference plot,eval=F}
spatial.plot(dfr$lon, dfr$lat, log(edat$wc)-log(edat$xi), inches=.1)
title("xCD vs Xia difference")
```
It may also be of interest to take a clustering approach to comparing model predictions...

```{r k-means-dendro,eval=F}
hc = hclust(dist(t(edat[,14:21])))
plot(hc)
```

# Next steps

1. Debug loglikelihood for Xia and gravity models
2. Include intercept term to capture background
1. Use negative binomial model
3. Compare with "null" models (diffusion, independent)
4. Model-model comparison of coupling matrices (which places are the strongest outliers) using likelihood residuals

Plots:

1. empirical CCS plot with residuals (how well do models capture the residuals?)
1. likelihood comparison maps

1. Expontial distance kernels
1. qAICs and qBayes-weights in table 
1. Solve optimization issues
1. Random effects.
1. Zero-inflated or negative binomial model?
1. Revisit $\sigma$ profile
1. Revisit TSIR fitting (include residuals?)
1. Include references for the various models.

# References
